{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98d57076",
   "metadata": {},
   "source": [
    "# 02. Agent Workflow Demo\n",
    "\n",
    "This notebook demonstrates the complete workflow of AgentCore, from planning to execution.\n",
    "\n",
    "## Workflow Steps\n",
    "1. Task Planning\n",
    "2. Plan Validation\n",
    "3. Execution\n",
    "4. Result Processing\n",
    "5. Memory Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e99451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Add project root to Python path\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the absolute path to the project root\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "# Print the updated path for verification\n",
    "# print(\"Updated Python path:\")\n",
    "# for path in sys.path:\n",
    "#     print(path)\n",
    "from agents.planning_agent import PlanningAgent\n",
    "from agents.execution_agent import ExecutionAgent\n",
    "from memory.ollama_embedding import get_ollama_embedding\n",
    "from memory.vector_memory import VectorMemory\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e8ec8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ToDo: Store in /configs/planning.yaml and read\n",
    "planning_config = {\n",
    "    \"model\": \"gpt-4\",\n",
    "    \"temperature\": 0.7,\n",
    "    \"max_tokens\": 1000,\n",
    "    \"system_prompt\": \"You are a planning agent that breaks down tasks into executable steps.\"\n",
    "}\n",
    "\n",
    "# Import tools from framework\n",
    "from tools import SearchTool\n",
    "import asyncio\n",
    "\n",
    "# Initialize tools\n",
    "tools = [SearchTool()]\n",
    "\n",
    "#ToDo: Store in /configs/execution.yaml and read\n",
    "execution_config = {\n",
    "    \"model\": \"gpt-4\",\n",
    "    \"temperature\": 0.7,\n",
    "    \"max_tokens\": 1000,\n",
    "    \"system_prompt\": \"You are an execution agent that carries out tasks step by step.\"\n",
    "}\n",
    "\n",
    "#ToDo: Store in /configs/memory.yaml and read\n",
    "memory_config = {\n",
    "    \"embedding_model\": \"ollama:mxbai-embed-large\",\n",
    "    \"index_name\": \"agent_memory\",\n",
    "    \"dimension\": 1024 #Hard output limit for mxbai-embed-large\n",
    "}\n",
    "\n",
    "# Initialize components with configuration\n",
    "planning_agent = PlanningAgent(config=planning_config)\n",
    "execution_agent = ExecutionAgent(config=execution_config, tools=tools)\n",
    "vector_memory = VectorMemory(config=memory_config, embedding_fn=get_ollama_embedding)\n",
    "\n",
    "# Example task\n",
    "task = \"Find a suitable homemade pasta recipe that supports hand-twisted pasta shapes.  Provide photos of the pasta shapes.\"\n",
    "\n",
    "async def generate_plan():\n",
    "    # Generate plan\n",
    "    plan = await planning_agent.plan(task)\n",
    "    print(\"Generated Plan:\")\n",
    "    for i, step in enumerate(plan, 1):\n",
    "        print(f\"{i}. {step['description']}\")\n",
    "    return plan\n",
    "\n",
    "# Run the async function\n",
    "plan = await generate_plan()  # Changed from asyncio.run() to await"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e237304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute plan\n",
    "async def execute_plan():\n",
    "    results = []\n",
    "    for step in plan:\n",
    "        print(f\"\\nExecuting: {step['description']}\")  # Access the description from the step dict\n",
    "        result = await execution_agent.execute(step)  # Changed to execute() and added await\n",
    "        results.append(result)\n",
    "        print(f\"Result: {result}\")\n",
    "    \n",
    "    # Store results in vector memory\n",
    "    vector_memory.add_memory(str(results))  # Changed from add_document to add_memory\n",
    "    return results\n",
    "\n",
    "# Run the execution\n",
    "results = await execute_plan()  # Changed from asyncio.run() to await"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
