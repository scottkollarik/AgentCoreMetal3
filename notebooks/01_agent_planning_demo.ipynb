{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4368919",
   "metadata": {},
   "source": [
    "# 01. Agent Planning Demo\n",
    "\n",
    "This notebook demonstrates the planning capabilities of AgentCore's planning agent. We'll explore:\n",
    "1. Basic task planning\n",
    "2. Complex task decomposition\n",
    "3. Plan validation and refinement\n",
    "\n",
    "## Example Tasks\n",
    "We'll work through these example tasks:\n",
    "1. Simple task: \"Create a summary of AI trends\"\n",
    "2. Medium task: \"Research and compare different AI frameworks\"\n",
    "3. Complex task: \"Analyze the impact of AI on healthcare and create a presentation\"\n",
    "\n",
    "## Expected Outputs\n",
    "For each task, you'll see:\n",
    "- A structured plan with clear steps\n",
    "- Validation of the plan's feasibility\n",
    "- Estimated time and resource requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1371a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import asyncio\n",
    "sys.path.append('..')\n",
    "\n",
    "from agents.planning_agent import PlanningAgent\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import display, HTML, Markdown\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47de1a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize planning agent with configuration\n",
    "config = {\n",
    "    \"model_name\": \"gpt-4\",  # or \"gpt-3.5-turbo\" for faster, less expensive results\n",
    "    \"temperature\": 0.7,     # Controls creativity vs. consistency\n",
    "    \"max_tokens\": 1000,     # Maximum length of generated plans\n",
    "    \"timeout\": 30,          # Timeout in seconds for API calls\n",
    "    \"debug\": True           # Enable debug logging by default \n",
    "}\n",
    "\n",
    "planning_agent = PlanningAgent(config)\n",
    "\n",
    "# Example 1: Simple task\n",
    "simple_task = \"Create a summary of AI trends\"\n",
    "print(f\"Task: {simple_task}\")\n",
    "\n",
    "# Generate plan using async/await\n",
    "async def generate_plan():\n",
    "    # Get the raw response from the LLM\n",
    "    response = await planning_agent.llm.ainvoke(\n",
    "        planning_agent.planning_prompt.format_messages(task=simple_task)\n",
    "    )\n",
    "    \n",
    "    print(\"\\nRaw LLM Response:\")\n",
    "    print(response.content)\n",
    "    \n",
    "    # Now try to parse it into steps\n",
    "    print(\"\\nAttempting to parse into steps...\")\n",
    "    plan = await planning_agent.plan(simple_task)\n",
    "    \n",
    "    print(\"\\nParsed Plan:\")\n",
    "    if not plan:\n",
    "        print(\"No steps were parsed from the response.\")\n",
    "    else:\n",
    "        for i, step in enumerate(plan, 1):\n",
    "            print(f\"{i}. {step['description']}\")\n",
    "\n",
    "# Run the async function in Jupyter\n",
    "await generate_plan()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f52d681",
   "metadata": {},
   "source": [
    "## Try Your Own Task\n",
    "\n",
    "Now it's your turn! Try creating a plan for your own task. Here are some tips:\n",
    "1. Be specific about what you want to achieve\n",
    "2. Consider dependencies between steps\n",
    "3. Think about required resources\n",
    "4. Consider potential challenges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdc4962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your task here\n",
    "your_task = \"\"  # Replace with your task\n",
    "\n",
    "if your_task:\n",
    "    async def generate_your_plan():\n",
    "        # Get the raw response from the LLM\n",
    "        response = await planning_agent.llm.ainvoke(\n",
    "            planning_agent.planning_prompt.format_messages(task=your_task)\n",
    "        )\n",
    "        \n",
    "        print(\"\\nRaw LLM Response:\")\n",
    "        print(response.content)\n",
    "        \n",
    "        # Now try to parse it into steps\n",
    "        print(\"\\nAttempting to parse into steps...\")\n",
    "        plan = await planning_agent.plan(your_task)\n",
    "        \n",
    "        print(\"\\nParsed Plan:\")\n",
    "        if not plan:\n",
    "            print(\"No steps were parsed from the response.\")\n",
    "        else:\n",
    "            for i, step in enumerate(plan, 1):\n",
    "                print(f\"{i}. {step['description']}\")\n",
    "    \n",
    "    await generate_your_plan()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
