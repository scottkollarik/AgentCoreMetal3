{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b75e193",
   "metadata": {},
   "source": [
    "# Debug Panel Demo\n",
    "\n",
    "This notebook demonstrates how to use the debug panel in AgentCore. The debug panel provides detailed information about:\n",
    "1. Step parsing process\n",
    "2. LLM responses\n",
    "3. Component interactions\n",
    "\n",
    "## How to Use\n",
    "1. Enable debug mode in the agent configuration\n",
    "2. The debug panel will automatically appear when running tasks\n",
    "3. Click on the panel to expand/collapse the debug information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30b7473",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_ollama_embedding(text, model=\"mxbai-embed-large\"):\n",
    "    url = \"http://localhost:11434/api/embeddings\"\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"prompt\": text\n",
    "    }\n",
    "    response = requests.post(url, json=payload)\n",
    "    response.raise_for_status()\n",
    "    return response.json()[\"embedding\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56e1274",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import asyncio\n",
    "sys.path.append('../..')\n",
    "\n",
    "from agents.planning_agent import PlanningAgent\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import display, HTML, Markdown\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3e7d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize planning agent with debug mode enabled\n",
    "config = {\n",
    "    \"model_name\": \"gpt-4\",\n",
    "    \"temperature\": 0.7,\n",
    "    \"max_tokens\": 1000,\n",
    "    \"debug\": True  # Enable debug mode\n",
    "}\n",
    "\n",
    "planning_agent = PlanningAgent(config)\n",
    "\n",
    "# Example task\n",
    "task = \"Create a simple to-do list for a software project\"\n",
    "print(f\"Task: {task}\")\n",
    "\n",
    "# Generate plan using async/await\n",
    "async def generate_plan():\n",
    "    # Get the raw response from the LLM\n",
    "    response = await planning_agent.llm.ainvoke(\n",
    "        planning_agent.planning_prompt.format_messages(task=task)\n",
    "    )\n",
    "    \n",
    "    print(\"\\nRaw LLM Response:\")\n",
    "    print(response.content)\n",
    "    \n",
    "    # Now try to parse it into steps\n",
    "    print(\"\\nAttempting to parse into steps...\")\n",
    "    plan = await planning_agent.plan(task)\n",
    "    \n",
    "    print(\"\\nParsed Plan:\")\n",
    "    if not plan:\n",
    "        print(\"No steps were parsed from the response.\")\n",
    "    else:\n",
    "        for i, step in enumerate(plan, 1):\n",
    "            print(f\"{i}. {step['description']}\")\n",
    "\n",
    "# Run the async function in Jupyter\n",
    "await generate_plan()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04dbe55",
   "metadata": {},
   "source": [
    "## Try Your Own Task\n",
    "\n",
    "Now try creating a plan for your own task. The debug panel will show you how the agent parses the steps from the LLM's response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ab629c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your task here\n",
    "your_task = \"\"  # Replace with your task\n",
    "\n",
    "if your_task:\n",
    "    async def generate_your_plan():\n",
    "        # Get the raw response from the LLM\n",
    "        response = await planning_agent.llm.ainvoke(\n",
    "            planning_agent.planning_prompt.format_messages(task=your_task)\n",
    "        )\n",
    "        \n",
    "        print(\"\\nRaw LLM Response:\")\n",
    "        print(response.content)\n",
    "        \n",
    "        # Now try to parse it into steps\n",
    "        print(\"\\nAttempting to parse into steps...\")\n",
    "        plan = await planning_agent.plan(your_task)\n",
    "        \n",
    "        print(\"\\nParsed Plan:\")\n",
    "        if not plan:\n",
    "            print(\"No steps were parsed from the response.\")\n",
    "        else:\n",
    "            for i, step in enumerate(plan, 1):\n",
    "                print(f\"{i}. {step['description']}\")\n",
    "    \n",
    "    await generate_your_plan()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
